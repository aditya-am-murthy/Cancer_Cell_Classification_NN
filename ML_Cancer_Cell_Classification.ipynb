{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk98o0Xc4sFp"
      },
      "source": [
        "###Unzip the Data File I've Shared (should take 1 minute)\n",
        "#####Note: the file path will differ per person; I'll show you how to find your file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2_opfltLOz0",
        "outputId": "7207d356-f358-430f-a149-5add9f45eaa7"
      },
      "outputs": [],
      "source": [
        "#!unzip /content/drive/MyDrive/CancerCellDataZip.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjQbNgLn4x8m"
      },
      "source": [
        "Import Commands for Python Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6d1m8T5A-bhl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/11/gc_2lxh111d5zg7cmv1m9db40000gp/T/ipykernel_12387/720323434.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from keras import utils\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1kEBQz042lk"
      },
      "source": [
        "Read the data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "hf24HmESLfd7",
        "outputId": "a10bc362-dfe8-4ed1-d71a-889089d0c24c"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/Users/adityacode/Downloads/Cell_ML_Classification/CancerCellDataZip\")\n",
        "\n",
        "#directory with training data for cancerous cell images\n",
        "train_cancer_dir = '/Users/adityacode/Downloads/Cell_ML_Classification/CancerCellDataZip/training_data/fold_0/all'\n",
        "#directory with training data for non-cancerous cell images\n",
        "train_normal_dir = '/Users/adityacode/Downloads/Cell_ML_Classification/CancerCellDataZip/training_data/fold_0/hem'\n",
        "\n",
        "#list of all the training data\n",
        "train_cancer_list = os.listdir(train_cancer_dir)\n",
        "train_normal_list = os.listdir(train_normal_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW5_n7KV47KL"
      },
      "source": [
        "Check if data files are read... the output should be 3527 if successful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYeGiqfY8ths",
        "outputId": "20ee6e47-e847-434c-c50f-297004136ffe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3527"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(([1] * len(train_cancer_list) + [0] * len(train_normal_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n8Bci-ZnMNmM"
      },
      "outputs": [],
      "source": [
        "#image generator to generate batches of images\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqkKbClNMPnU",
        "outputId": "4ec3b3ee-1ab5-4ab5-dd6e-444fa38a7357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3527 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/Users/adityacode/Downloads/Cell_ML_Classification/CancerCellDataZip/training_data/fold_0',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8fXA7Ty25443"
      },
      "outputs": [],
      "source": [
        "#model architecture\n",
        "input_shape = (150, 150, 3)\n",
        "\n",
        "# Define architecture\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OqPf_U8lMYdl"
      },
      "outputs": [],
      "source": [
        "#compile model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                optimizer=keras.optimizers.legacy.RMSprop(learning_rate=0.003),\n",
        "                metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_7voKD0GBH1",
        "outputId": "c0772881-f35d-44f9-a757-dc796ac09773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "8/8 [==============================] - 7s 750ms/step - loss: 3.0810 - acc: 0.5459\n",
            "Epoch 2/15\n",
            "8/8 [==============================] - 6s 715ms/step - loss: 0.6269 - acc: 0.6270\n",
            "Epoch 3/15\n",
            "8/8 [==============================] - 6s 702ms/step - loss: 0.5177 - acc: 0.7656\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 6s 704ms/step - loss: 0.4746 - acc: 0.8213\n",
            "Epoch 5/15\n",
            "8/8 [==============================] - 6s 715ms/step - loss: 0.4584 - acc: 0.8174\n",
            "Epoch 6/15\n",
            "8/8 [==============================] - 6s 702ms/step - loss: 0.4863 - acc: 0.7637\n",
            "Epoch 7/15\n",
            "8/8 [==============================] - 5s 665ms/step - loss: 0.5559 - acc: 0.7694\n",
            "Epoch 8/15\n",
            "8/8 [==============================] - 6s 715ms/step - loss: 0.4235 - acc: 0.8291\n",
            "Epoch 9/15\n",
            "8/8 [==============================] - 6s 721ms/step - loss: 0.4319 - acc: 0.8304\n",
            "Epoch 10/15\n",
            "8/8 [==============================] - 6s 712ms/step - loss: 0.4293 - acc: 0.8418\n",
            "Epoch 11/15\n",
            "8/8 [==============================] - 6s 674ms/step - loss: 0.4574 - acc: 0.8097\n",
            "Epoch 12/15\n",
            "8/8 [==============================] - 6s 680ms/step - loss: 0.4637 - acc: 0.8201\n",
            "Epoch 13/15\n",
            "8/8 [==============================] - 6s 722ms/step - loss: 0.4682 - acc: 0.8027\n",
            "Epoch 14/15\n",
            "8/8 [==============================] - 6s 712ms/step - loss: 0.4461 - acc: 0.8086\n",
            "Epoch 15/15\n",
            "8/8 [==============================] - 6s 685ms/step - loss: 0.4773 - acc: 0.8335\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x173c57810>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import scipy\n",
        "#train model\n",
        "model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=8,\n",
        "        epochs=15,\n",
        "        verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfK--hBD5eac"
      },
      "source": [
        "## STOP HERE! DO NOT RUN THE CODE BELOW (it takes a long time to run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4Eu-kcOD_e5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Create the scaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Flatten the images into a single array\n",
        "X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
        "\n",
        "# Fit the scaler to the training data\n",
        "scaler.fit(X_train_flat)\n",
        "\n",
        "# Transform the training data\n",
        "X_train_scaled = scaler.transform(X_train_flat)\n",
        "\n",
        "# Reshape the transformed data back into image format\n",
        "X_train_scaled = X_train_scaled.reshape(*X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0VYHoQ-vLlG"
      },
      "outputs": [],
      "source": [
        "###Don't run this cell\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "ann_estimator = KerasRegressor(build_fn= model, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "# Create the AdaBoost classifier\n",
        "adaboost = AdaBoostRegressor(base_estimator=ann_estimator)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "ann_estimator.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f8S6LK7MRND"
      },
      "outputs": [],
      "source": [
        "#create a CNN model with ResNet50 layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "conv_base = ResNet50(weights='imagenet',\n",
        "                    include_top=False,\n",
        "                    input_shape=(150, 150, 3))\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(256, activation='relu'))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwZT8dua8aJA"
      },
      "outputs": [],
      "source": [
        "# DataFrame using arrays.\n",
        "\n",
        "X_train_list = []\n",
        "y_train_list = ([1] * len(train_cancer_list) + [0] * len(train_normal_list))\n",
        "\n",
        "\n",
        "X_train_names = np.array(train_cancer_list + train_normal_list)\n",
        "y_train = np.array(y_train_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j44SNqlpCAPC"
      },
      "outputs": [],
      "source": [
        "boosted_ann = AdaBoostRegressor(base_estimator= ann_estimator)\n",
        "boosted_ann.fit(rescaledX, y_train.values.ravel())# scale your training data\n",
        "boosted_ann.predict(rescaledX_Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG7QkFrtMd_Q"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhhMXQ6e35G6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
